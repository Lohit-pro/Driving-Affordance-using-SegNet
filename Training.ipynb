{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "lONc6IUZLfA9",
        "outputId": "1d58cebc-9ab1-45e8-da2f-40f332f8d3de"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW3HLkRRyqQk",
        "outputId": "acc55246-90df-48f9-abe4-d7c4901dcb0f"
      },
      "outputs": [],
      "source": [
        "pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kLbqN-cMHWh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import tqdm\n",
        "import torch\n",
        "import datetime\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "from skimage import img_as_float\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tj3lYX7MHuP"
      },
      "outputs": [],
      "source": [
        "root = \"/content/drive/MyDrive/C_scapes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC9jBNdjMNRK"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5fZiPHRMQ2l"
      },
      "outputs": [],
      "source": [
        "model_choice = 'segnet' # Select which model to train / test, can be 'fcn' or 'segnet'\n",
        "weighted_choice = False # Select if loss function should be weighted or not\n",
        "train = False # Select if you want to train or evaluate the model\n",
        "img_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ2olGHgMTEx"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bab46WCMUgt"
      },
      "outputs": [],
      "source": [
        "class _DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_conv_layers):\n",
        "        super(_DecoderBlock, self).__init__()\n",
        "        middle_channels = in_channels // 2\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels, middle_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(middle_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "        layers += [\n",
        "                      nn.Conv2d(middle_channels, middle_channels, kernel_size=3, padding=1),\n",
        "                      nn.BatchNorm2d(middle_channels),\n",
        "                      nn.ReLU(inplace=True),\n",
        "                  ] * (num_conv_layers - 2)\n",
        "        layers += [\n",
        "            nn.Conv2d(middle_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        self.decode = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decode(x)\n",
        "\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(SegNet, self).__init__()\n",
        "        vgg = torchvision.models.vgg19_bn(pretrained=True)\n",
        "        features = list(vgg.features.children())\n",
        "        self.enc1 = nn.Sequential(*features[0:7])\n",
        "        self.enc2 = nn.Sequential(*features[7:14])\n",
        "        self.enc3 = nn.Sequential(*features[14:27])\n",
        "        self.enc4 = nn.Sequential(*features[27:40])\n",
        "        self.enc5 = nn.Sequential(*features[40:])\n",
        "\n",
        "        self.dec5 = nn.Sequential(\n",
        "            *([nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2)] +\n",
        "              [nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "               nn.BatchNorm2d(512),\n",
        "               nn.ReLU(inplace=True)] * 4)\n",
        "        )\n",
        "        self.dec4 = _DecoderBlock(1024, 256, 4)\n",
        "        self.dec3 = _DecoderBlock(512, 128, 4)\n",
        "        self.dec2 = _DecoderBlock(256, 64, 2)\n",
        "        self.dec1 = _DecoderBlock(128, num_classes, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(enc1)\n",
        "        enc3 = self.enc3(enc2)\n",
        "        enc4 = self.enc4(enc3)\n",
        "        enc5 = self.enc5(enc4)\n",
        "\n",
        "        dec5 = self.dec5(enc5)\n",
        "        dec4 = self.dec4(torch.cat([enc4, dec5], 1))\n",
        "        dec3 = self.dec3(torch.cat([enc3, dec4], 1))\n",
        "        dec2 = self.dec2(torch.cat([enc2, dec3], 1))\n",
        "        dec1 = self.dec1(torch.cat([enc1, dec2], 1))\n",
        "        return dec1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evLJB2IiMW8l",
        "outputId": "bf7be49d-5895-4c7d-a2fa-6b919d2d4c18"
      },
      "outputs": [],
      "source": [
        "if model_choice == 'fcn':\n",
        "    model = FCN8s(39).to(device)\n",
        "else:\n",
        "    model = SegNet(39).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k911fZLvMZA9"
      },
      "outputs": [],
      "source": [
        "batch = 16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDSADBx_MbDk"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "        transforms.Resize((img_size,img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "        transforms.Resize((img_size,img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66V5cLAfMeCu"
      },
      "outputs": [],
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, root, size, train=True, data_transforms=None):\n",
        "        self.root = root\n",
        "        if train:\n",
        "            self.img_path = root + '/img/' + '/subset_train/'\n",
        "            self.seg_path = root + '/seg/' + '/subset_train/'\n",
        "        else:\n",
        "            self.img_path = root + '/img/' + '/subset_val/'\n",
        "            self.seg_path = root + '/seg/' + '/subset_val/'\n",
        "\n",
        "        self.img_list, self.seg_list = os.listdir(self.img_path), os.listdir(self.seg_path)\n",
        "        self.size = size\n",
        "        self.data_transforms = data_transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(os.path.join(self.img_path, self.img_list[index]))\n",
        "        img = self.data_transforms(img)\n",
        "\n",
        "        seg = cv2.resize(cv2.imread(os.path.join(self.seg_path, self.seg_list[index])), self.size, cv2.INTER_NEAREST)\n",
        "        seg = torch.from_numpy(seg[:,:,0]).long()\n",
        "\n",
        "        return img, seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYBmGUhcMyci"
      },
      "outputs": [],
      "source": [
        "#train_dataset = SegmentationDataset('/content/drive/MyDrive/Cityscapes/final_train/', (img_size,img_size), data_transforms=train_transforms)\n",
        "#train_dataloader = DataLoader(train_dataset, num_workers=2, shuffle=True, batch_size=batch)\n",
        "\n",
        "test_dataset = SegmentationDataset('/content/drive/MyDrive/C_scapes/', (img_size,img_size), data_transforms=test_transforms, train=False)\n",
        "test_dataloader = DataLoader(test_dataset, num_workers=2, shuffle=True, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "WDqAL1g2NY-I",
        "outputId": "b002c851-ba68-4358-f085-c572fc009eef"
      },
      "outputs": [],
      "source": [
        "for i, data in enumerate(train_dataloader):\n",
        "    print(data[0].shape, data[1].shape)\n",
        "    print(np.unique(data[1].numpy()))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qY3K_3BNZpo"
      },
      "outputs": [],
      "source": [
        "if not train:\n",
        "    #path_fcn_unweighted = './all_models/fcn/models/fcn_upsample_best.pth'\n",
        "    path_segnet_unweighted = '/content/drive/MyDrive/C_scapes/segnet/models/segnet_upsample_best.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SQGG-xCNiF8"
      },
      "outputs": [],
      "source": [
        "def checkAccuracy(pred, truth, batch_size):\n",
        "    pred = pred.cpu().numpy()\n",
        "    truth = truth.cpu().numpy()\n",
        "    acc = np.count_nonzero(pred==truth) / (256*256*batch_size)\n",
        "    return acc\n",
        "\n",
        "def checkiou(pred, truth):\n",
        "    intersection = pred & truth\n",
        "    union = pred | truth\n",
        "    iou = torch.mean((torch.sum(intersection).float()/torch.sum(union).float()).float())\n",
        "    return iou\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def find_weights(dataset, num_classes):\n",
        "    weights = np.ones((num_classes, 1))\n",
        "    for i, data in enumerate(dataset):\n",
        "        seg = data[1].numpy()\n",
        "        cl, count = np.unique(seg, return_counts=True)\n",
        "        for j in range(len(cl)):\n",
        "            weights[cl[j]] += count[j]\n",
        "    weights = weights / np.sum(weights)\n",
        "    return np.reshape(np.reciprocal(weights), (weights.shape[0],1))\n",
        "\n",
        "def checkclasswisedice(y_true, predicted, k=1):\n",
        "    labels = np.unique(y_true)\n",
        "    if k in labels:\n",
        "        dice_score = 2.0 * np.sum(predicted[y_true==k]==k) / (np.sum(predicted[y_true==k]==k) + np.sum(y_true[y_true==k]==k))\n",
        "        return dice_score, 1\n",
        "    dice_score = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1XbRH5bNj90"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = '/content/drive/MyDrive/C_scapes/'\n",
        "now = model_choice\n",
        "\n",
        "if not os.path.exists(ROOT_DIR):\n",
        "    os.makedirs(ROOT_DIR)\n",
        "\n",
        "if not os.path.exists(ROOT_DIR + now):\n",
        "    os.makedirs(ROOT_DIR + now)\n",
        "\n",
        "LOG_DIR = ROOT_DIR + now + '/logs/'\n",
        "if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "\n",
        "MODEL_DIR = ROOT_DIR + now + '/models/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.makedirs(MODEL_DIR)\n",
        "\n",
        "summary_writer = SummaryWriter(LOG_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA4gRxiRNoGe"
      },
      "outputs": [],
      "source": [
        "if weighted_choice:\n",
        "    weights = torch.from_numpy(find_weights(train_dataset, 39)).float().to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weights).to(device)\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "max_epoch = 50\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=1.0e-3, betas=(0.9,0.999), weight_decay=1.0e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em1qfnbZNr-n"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, val_set):\n",
        "    total_acc, total_iou = 0, 0\n",
        "    total_count = len(val_set)\n",
        "    print('Total number of samples in the evaluation set is ', len(val_set))\n",
        "\n",
        "    val_loader = DataLoader(val_set, num_workers=2, shuffle=False, batch_size=1)\n",
        "\n",
        "    model.eval()\n",
        "    len_dataloader = len(val_loader)\n",
        "    for i, data in enumerate(val_loader):\n",
        "        imgs = data[0].float().to(device)\n",
        "        labels = data[1].long().to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out= model(imgs)\n",
        "\n",
        "        out_labels = torch.argmax(out, dim=1)\n",
        "\n",
        "        prediction = out_labels.cpu().numpy()\n",
        "        truth = labels.cpu().numpy()\n",
        "        acc = np.count_nonzero(prediction == truth) / (img_size*img_size)\n",
        "        total_acc += acc\n",
        "\n",
        "        iou = checkiou(out_labels, labels)\n",
        "        total_iou += iou\n",
        "\n",
        "    return total_acc / total_count, total_iou / total_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMidBbjJNsj9"
      },
      "outputs": [],
      "source": [
        "def visualize(model, val_set):\n",
        "    index = np.random.randint(len(val_set))\n",
        "    data = val_set.__getitem__(0)\n",
        "    imgs = data[0].unsqueeze(0).float().to(device)\n",
        "    labels = data[1].unsqueeze(0).long().to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out= model(imgs)\n",
        "\n",
        "    print(out)\n",
        "\n",
        "    out_labels = torch.argmax(out, dim=1)\n",
        "\n",
        "    img = imgs[0,:,:,:].permute(1,2,0).detach().cpu().numpy()\n",
        "    gt = labels[0,:,:].detach().cpu().numpy()\n",
        "    pred = out_labels[0,:,:].detach().cpu().numpy()\n",
        "\n",
        "    return img, gt, pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbYL6I5UFmzp"
      },
      "outputs": [],
      "source": [
        "def visualize(model, val_set):\n",
        "    index = np.random.randint(len(val_set))\n",
        "    data = val_set.__getitem__(0)\n",
        "    imgs = data[0].unsqueeze(0).float().to(device)\n",
        "    labels = data[1].unsqueeze(0).long().to(device)\n",
        "\n",
        "    print('imgs:', imgs.shape)\n",
        "    print('labels:', labels.shape)\n",
        "\n",
        "    out = None\n",
        "    with torch.no_grad():\n",
        "        out = model(imgs)\n",
        "        print('out:', out.shape)\n",
        "\n",
        "    out_labels = torch.argmax(out, dim=1)\n",
        "\n",
        "    img = imgs[0,:,:,:].permute(1,2,0).detach().cpu().numpy()\n",
        "    gt = labels[0,:,:].detach().cpu().numpy()\n",
        "    pred = out_labels[0,:,:].detach().cpu().numpy()\n",
        "\n",
        "    return img, gt, pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwZ1INjvQ6n9"
      },
      "outputs": [],
      "source": [
        "#correct\n",
        "def visualize(model, val_set):\n",
        "    index = np.random.randint(len(val_set))\n",
        "    data = val_set.__getitem__(0)\n",
        "    imgs = data[0].unsqueeze(0).float().to(device)\n",
        "    labels = data[1].unsqueeze(0).long().to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(imgs)\n",
        "        out_channel1 = out[:, 1, :, :]\n",
        "        out_labels = torch.argmax(out, dim=1)\n",
        "\n",
        "    img = imgs[0,:,:,:].permute(1,2,0).detach().cpu().numpy()\n",
        "    gt = labels[0,:,:].detach().cpu().numpy()\n",
        "    pred = out_labels[0,:,:].detach().cpu().numpy()\n",
        "\n",
        "    return img, gt, pred, out_channel1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOSDtps4OzSp"
      },
      "outputs": [],
      "source": [
        "path_segnet_unweighted = '/content/drive/MyDrive/C_scapes/segnet/models/segnet_upsample_best.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTNvxIWXNyPw",
        "outputId": "b5df3e9e-a2ed-47ee-93ba-d27a562edc44"
      },
      "outputs": [],
      "source": [
        "model = SegNet(39).to(device)\n",
        "model.load_state_dict(torch.load(path_segnet_unweighted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuXXpAKCN92K",
        "outputId": "204d7ab8-f2c2-4e04-9964-2b2297473c6b"
      },
      "outputs": [],
      "source": [
        "img, gt, pred = visualize(model, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL86MWLjRA98"
      },
      "outputs": [],
      "source": [
        "img, gt, pred, out_channel1 = visualize(model, test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvDVr2yGUrKy"
      },
      "outputs": [],
      "source": [
        "image = pred\n",
        "#h,w = img.shape\n",
        "#h = int(h/2)\n",
        "#w = int(w/2)\n",
        "\n",
        "#print(img[h,w])\n",
        "#x = img[h,w]\n",
        "\n",
        "h,w = image.shape\n",
        "\n",
        "for i in range(0,h):\n",
        "  for j in range(0,w):\n",
        "    if(image[i,j] != 1):\n",
        "      image[i,j] = 0\n",
        "    else :\n",
        "      image[i,j] = 255*image[i,j]\n",
        "\n",
        "#plt.imshow(image, label='Output of U-SegNet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRLxF8qhOMzO",
        "outputId": "aa597ceb-8c11-4d4a-bdb7-64f2dfda017a"
      },
      "outputs": [],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm90qq13K1dK"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,60))\n",
        "ax_top_1 = fig.add_subplot(131)\n",
        "ax_top_1.set_axis_off()\n",
        "plt.imshow(img, label='Input MRI')\n",
        "ax_top_2 = fig.add_subplot(132)\n",
        "ax_top_2.set_axis_off()\n",
        "plt.imshow(gt, label='Ground truth')\n",
        "ax_top_3 = fig.add_subplot(133)\n",
        "ax_top_3.set_axis_off()\n",
        "plt.imshow(image, label='Output of U-SegNet')\n",
        "plt.show()\n",
        "fig.savefig('/content/drive/MyDrive/Cityscapes/final_train/segnet.png', bbox_inches = 'tight', pad_inches = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "jxekNeBXRfZL",
        "outputId": "7f1c55b6-96b8-4e39-a91a-ad4cf415d50f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# assuming out_channel1 is a tensor with shape [1, 256, 256]\n",
        "out_channel1 = out_channel1[0].detach().cpu().numpy()\n",
        "\n",
        "# display the image\n",
        "plt.imshow(out_channel1)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "IFPcxCVedH8Y",
        "outputId": "0a50356c-3a0c-4f88-8ed0-f1a07f2ea329"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,60))\n",
        "ax_top_1 = fig.add_subplot(131)\n",
        "ax_top_1.set_axis_off()\n",
        "plt.imshow(img, label='Input MRI')\n",
        "ax_top_2 = fig.add_subplot(132)\n",
        "ax_top_2.set_axis_off()\n",
        "plt.imshow(gt, label='Ground truth')\n",
        "ax_top_3 = fig.add_subplot(133)\n",
        "ax_top_3.set_axis_off()\n",
        "plt.imshow(image, label='Output of U-SegNet')\n",
        "plt.show()\n",
        "fig.savefig('/content/drive/MyDrive/Cityscapes/final_train/segnet.png', bbox_inches = 'tight', pad_inches = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "x79UfuzbdIVt",
        "outputId": "4ec735f8-afe5-4a6d-ad66-63a1ef11b3dd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,60))\n",
        "ax_top_1 = fig.add_subplot(131)\n",
        "ax_top_1.set_axis_off()\n",
        "plt.imshow(img, label='Input MRI')\n",
        "ax_top_2 = fig.add_subplot(132)\n",
        "ax_top_2.set_axis_off()\n",
        "plt.imshow(gt, label='Ground truth')\n",
        "ax_top_3 = fig.add_subplot(133)\n",
        "ax_top_3.set_axis_off()\n",
        "plt.imshow(image, label='Output of U-SegNet')\n",
        "plt.show()\n",
        "fig.savefig('/content/drive/MyDrive/Cityscapes/final_train/segnet.png', bbox_inches = 'tight', pad_inches = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "hZsmaUd6ofOm",
        "outputId": "732bb468-0c82-45a3-8205-847a0a672da8"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,60))\n",
        "ax_top_1 = fig.add_subplot(131)\n",
        "ax_top_1.set_axis_off()\n",
        "plt.imshow(img, label='Input MRI')\n",
        "ax_top_2 = fig.add_subplot(132)\n",
        "ax_top_2.set_axis_off()\n",
        "plt.imshow(gt, label='Ground truth')\n",
        "ax_top_3 = fig.add_subplot(133)\n",
        "ax_top_3.set_axis_off()\n",
        "plt.imshow(image, label='Output of U-SegNet')\n",
        "plt.show()\n",
        "fig.savefig('/content/drive/MyDrive/Cityscapes/final_train/segnet.png', bbox_inches = 'tight', pad_inches = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "6watOdxvybmP",
        "outputId": "7f9e7969-c9f3-40ef-dc48-bb6401bb66e0"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,60))\n",
        "ax_top_1 = fig.add_subplot(131)\n",
        "ax_top_1.set_axis_off()\n",
        "plt.imshow(img, label='Input MRI')\n",
        "ax_top_2 = fig.add_subplot(132)\n",
        "ax_top_2.set_axis_off()\n",
        "plt.imshow(gt, label='Ground truth')\n",
        "#ax_top_3 = fig.add_subplot(133)\n",
        "#ax_top_3.set_axis_off()\n",
        "#plt.imshow(image, label='Output of U-SegNet')\n",
        "plt.show()\n",
        "fig.savefig('/content/drive/MyDrive/Cityscapes/final_train/segnet.png', bbox_inches = 'tight', pad_inches = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "FavgfGJb0CMx",
        "outputId": "d0ffdecf-7780-4721-bece-528ac5c9b79b"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,60))\n",
        "ax_top_1 = fig.add_subplot(131)\n",
        "ax_top_1.set_axis_off()\n",
        "plt.imshow(img, label='Input MRI')\n",
        "ax_top_2 = fig.add_subplot(132)\n",
        "ax_top_2.set_axis_off()\n",
        "plt.imshow(gt, label='Ground truth')\n",
        "#ax_top_3 = fig.add_subplot(133)\n",
        "#ax_top_3.set_axis_off()\n",
        "#plt.imshow(image, label='Output of U-SegNet')\n",
        "plt.show()\n",
        "fig.savefig('/content/drive/MyDrive/Cityscapes/final_train/segnet.png', bbox_inches = 'tight', pad_inches = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs3ngnK9J59i"
      },
      "outputs": [],
      "source": [
        "Sfrom PIL import Image\n",
        "\n",
        "# Open the image file\n",
        "image = Image.open('/content/drive/MyDrive/C_scapes/img/subset_val/img1.BMP')\n",
        "\n",
        "# Resize the image to the desired dimensions\n",
        "resized_image = image.resize((2048, 1024))\n",
        "\n",
        "# Save the resized image\n",
        "resized_image.save('/content/drive/MyDrive/C_scapes/img/subset_val/img1.BMP')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
